<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8"/>
  <title>VR App</title>
  <script src="https://cdn.babylonjs.com/babylon.js"></script>
</head>
<body>
<canvas id="renderCanvas" style="width:100%; height:100%;"></canvas>
<script>
const canvas = document.getElementById("renderCanvas");
const engine = new BABYLON.Engine(canvas, true);
const scene = new BABYLON.Scene(engine);

new BABYLON.HemisphericLight("light", new BABYLON.Vector3(1,1,0), scene);
const ground = BABYLON.MeshBuilder.CreateGround("ground", {width:10, height:10}, scene);

// Add some cubes
for (let i=0;i<5;i++){
  let box = BABYLON.MeshBuilder.CreateBox("b"+i,{size:0.3},scene);
  box.position.set(Math.random()*2-1,1.5,Math.random()*2-1);
}

// --- WebSocket Signaling ---
const ws = new WebSocket(`wss://${window.location.host}`);
function safeSend(data) {
  if (ws.readyState === WebSocket.OPEN) {
    ws.send(JSON.stringify(data));
  } else {
    ws.addEventListener("open", () => ws.send(JSON.stringify(data)), { once: true });
  }
}

let pc = new RTCPeerConnection({
  iceServers: [{ urls: "stun:stun.l.google.com:19302" }]
});

ws.onopen = () => {
  safeSend({ type:"register", role:"vr" });
};

pc.onicecandidate = e=>{
  if(e.candidate){
    safeSend({ type:"ice", role:"vr", candidate:e.candidate });
  }
};

// Track active stacked messages
let activeMessages = [];

ws.onmessage = async (event)=>{
  const data = JSON.parse(event.data);

  if(data.type==="answer"){
    await pc.setRemoteDescription(new RTCSessionDescription(data.answer));
  }
  else if(data.type==="ice"){
    await pc.addIceCandidate(new RTCIceCandidate(data.candidate));
  }
  else if(data.type==="annotation"){
    // ✅ FIX: use render size for picking
    const screenX = data.x * engine.getRenderWidth();
    const screenY = data.y * engine.getRenderHeight();

    const pickRay = scene.createPickingRay(screenX, screenY, BABYLON.Matrix.Identity(), scene.activeCamera);
    const hit = scene.pickWithRay(pickRay);

    let pos;
    if (hit.pickedPoint) {
      pos = hit.pickedPoint.add(new BABYLON.Vector3(0,0.2,0));
    } else {
      pos = scene.activeCamera.position.add(
        scene.activeCamera.getDirection(BABYLON.Axis.Z).scale(2)
      );
    }

    const arrow = BABYLON.MeshBuilder.CreateCylinder("arrow",{diameterTop:0,diameterBottom:0.1,height:0.5},scene);
    arrow.position = pos;
    const mat = new BABYLON.StandardMaterial("m",scene);
    mat.diffuseColor = new BABYLON.Color3(1,0,0);
    arrow.material = mat;

    // Optional: auto-remove after 5s
    setTimeout(() => arrow.dispose(), 5000);
  }
  else if (data.type === "text") {
    // --- Floating text in front of the user ---
    const plane = BABYLON.MeshBuilder.CreatePlane("textPlane", { size: 1.5 }, scene);

    const basePos = scene.activeCamera.position.add(
      scene.activeCamera.getDirection(BABYLON.Axis.Z).scale(2)
    );

    const offsetY = -0.5 * activeMessages.length;
    plane.position = basePos.add(new BABYLON.Vector3(0, offsetY, 0));

    plane.billboardMode = BABYLON.Mesh.BILLBOARDMODE_ALL;

    const dynamicTexture = new BABYLON.DynamicTexture("DynamicTexture", {width:512, height:256}, scene, true);
    dynamicTexture.drawText(data.text, null, 140, "bold 60px Arial", "white", "transparent", true);

    const mat = new BABYLON.StandardMaterial("textMat", scene);
    mat.diffuseTexture = dynamicTexture;
    mat.emissiveColor = new BABYLON.Color3(1, 1, 1);
    mat.alpha = 1;
    plane.material = mat;

    activeMessages.push({ plane, mat, dynamicTexture });

    // Smooth fade-out after 3s
    setTimeout(() => {
      scene.registerBeforeRender(() => {
        if (mat.alpha > 0) {
          mat.alpha -= 0.02;
          if (mat.alpha <= 0) {
            plane.dispose();
            dynamicTexture.dispose();
            activeMessages = activeMessages.filter(m => m.plane !== plane);
          }
        }
      });
    }, 3000);
  }
};

// --- WebXR (Immersive Mode) ---
async function initXR() {
  await scene.createDefaultXRExperienceAsync({ floorMeshes: [ground] });

  // ⚠️ Note: canvas.captureStream() will only show purple in immersive mode.
  // True headset view must be taken from Quest Casting.
  const stream = canvas.captureStream(30);
  stream.getTracks().forEach(track => pc.addTrack(track, stream));
  startStream();
}

async function startStream() {
  const offer = await pc.createOffer();
  await pc.setLocalDescription(offer);
  safeSend({ type:"offer", role:"vr", offer });
}

initXR();
engine.runRenderLoop(()=>scene.render());
</script>
</body>
</html>
